parameters
{
	numSamplesPerImage 1 ; How many Monte Carlo samples to generate per training image. Default: 10
	numCascadeSteps 2 ; How many cascade steps to learn?
	regularisationFactor 0.5 ; A value by which the default norm... is scaled.
	regulariseAffineComponent 1 ; 0 | 1
	regulariseWithEigenvalueThreshold 0 ; 0 | 1. If 1, lambda is set to the smallest eigenvalue, if 0, the standard regularisation is used, including the regularisationFactor given above.
	
	; mean, vj/all, etc... 
	
	featureDescriptors ; required parameter
	{
		0 ; note: please give the right order here, they will be pushed back in this order.
		{
			;descriptorType vlhog-uoctti # supported: OpenCVSift | vlhog-dt ('05, 4*numOrientations) | vlhog-uoctti (Felzenszwalb '09: PCA and stuff. 4+3*numOrientations) (which one is e-hog? seems to be the default in Matlab?); not yet supported: hog (peter) | e-hog (peter) | surf (peter)
			descriptorType OpenCVSift
			;descriptorPostprocessing none ; Not yet supported. pca on features yes/no, preserve percent (featurePostProcessing)
			;descriptorParameters "numCells 3 cellSize 12 numBins 4" ; For OpenCVSift: none so far; For vlhog-dt and vlhog-uoctti: numCells, cellSize, numBins; Note: Keep exactly that order of parameters! // numCells is Zhenhua's "cellSize" // numBins is the number of orientations. // cellSize is the size of a HOG cell (should be even) // numCells * cellSize = the patch width
		}
		1
		{
			;descriptorType vlhog-uoctti
			descriptorType OpenCVSift
			;descriptorPostprocessing none
			;descriptorParameters "numCells 3 cellSize 12 numBins 4"
		}
		2
		{
			;descriptorType vlhog-uoctti
			descriptorType OpenCVSift
			;descriptorParameters "numCells 2 cellSize 12 numBins 4"
		}
		3
		{
			;descriptorType vlhog-uoctti
			descriptorType OpenCVSift
			;descriptorParameters "numCells 2 cellSize 12 numBins 4"
		}
		4
		{
			;descriptorType vlhog-uoctti
			descriptorType OpenCVSift
			;descriptorParameters "numCells 1 cellSize 12 numBins 4"
		}
	
	}
}

modelLandmarks ; Parameters specifying the model that is to be trained
{
	landmarkType ibug ; The type/format of the landmarks, so the detection code can associate semantic meaning with the landmarks if needed
	; Q/Note: There might be a difference between landmark file format and the landmark type (e.g. the numbering). That could be a problem when other ibug-databases use the ibug-format but have different number of points. But that case might not exist.
	landmarks ;all; (optional parameter: 'all') What landmarks to use and how we name them. Also, the model will have the landmarks in this order. If 'all' is used, all the trainingData given below has to have the same number of landmarks with the same identifiers!
	{ ; we use the numbering from ibug-lfpw
		;9 ; chin
		;31 ; nose-tip
		;32 ; nose-right
		;36 ; nose-left
		37 ; right-eye outer
		;38
		;39
		40 ; right-eye inner
		;41
		;42
		43 ; left-eye inner
		;44
		;45
		46 ; left-eye outer
		;47
		;48
		49 ; right mouth corner
		;52
		55 ; left mouth corner
		;58
		;63
		;67
	}
}
trainingData ; The data to train the model
{
	ibug-lfpw ; Just a name for the database
	{
		images C:\\Users\\Patrik\\Documents\\GitHub\\data\\iBug_lfpw\\trainset_s5\\ ; A folder or file-list
		groundtruth C:\\Users\\Patrik\\Documents\\GitHub\\data\\iBug_lfpw\\trainset_s5\\ ; folder
		landmarkType ibug ; ibug | ...
		landmarkMappings none ; (optional parameter: 'none', meaning it's a 1:1 mapping to the modelLandmarks used) The mapping from our defined landmarks (lhs) to the lfpw ones (rhs)
		{
			;1 1
			;2 2
			;3 3
			; etc.
		}
	}
	
}
